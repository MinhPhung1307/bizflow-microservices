import os
import json
import uvicorn
import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File
from dotenv import load_dotenv
from app.models import NaturalLanguageOrderRequest, DraftOrderResponse, ProductSyncRequest
from app.services.rag_service import rag_service
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core import exceptions

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

app = FastAPI(title="BizFlow AI Service (Stable)")

# --- C·∫§U H√åNH MODEL ---
# S·ª¨ D·ª§NG 1.5 FLASH ƒê·ªÇ C√ì QUOTA CAO H∆†N, √çT B·ªä L·ªñI 429
GENERATIVE_MODEL_NAME = "gemini-2.5-flash" 

@app.post("/api/products/sync")
async def sync_products(request: ProductSyncRequest):
    data = [p.dict() for p in request.products]
    rag_service.sync_products(request.owner_id, data)
    return {"status": "success", "count": len(data)}

# --- H√ÄM G·ªåI GEMINI C√ì C∆† CH·∫æ RETRY ---
# N·∫øu g·∫∑p l·ªói 429 (ResourceExhausted), t·ª± ƒë·ªông ƒë·ª£i v√† th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn
@retry(
    retry=retry_if_exception_type(exceptions.ResourceExhausted),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def generate_content_safe(model, prompt):
    return model.generate_content(prompt)

async def parse_order_with_rag(message: str, owner_id: str) -> DraftOrderResponse:
    try:
        # 1. T√¨m ki·∫øm RAG (Gi·ªØ nguy√™n)
        relevant_products = rag_service.search_products(owner_id, message)
        
        context_str = ""
        if relevant_products:
            context_str = "DANH S√ÅCH S·∫¢N PH·∫®M TRONG KHO (G·ª£i √Ω):\n"
            for p in relevant_products:
                context_str += f"- T√™n: {p['original_name']} | Gi√°: {p['price']} | ƒê∆°n v·ªã: {p['unit']}\n"
        else:
            context_str = "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o trong kho kh·ªõp v·ªõi c√¢u n√≥i."

        # 2. G·ªçi Gemini - C·∫¨P NH·∫¨T PROMPT T·∫†I ƒê√ÇY
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        prompt = f"""
        B·∫°n l√† tr·ª£ l√Ω b√°n h√†ng th√¥ng minh. Nhi·ªám v·ª•: Tr√≠ch xu·∫•t th√¥ng tin ƒë∆°n h√†ng t·ª´ c√¢u n√≥i t·ª± nhi√™n ti·∫øng Vi·ªát th√†nh JSON.

        {context_str}

        QUY T·∫ÆC QUAN TR·ªåNG:
        1. **customer_name**: 
           - T√¨m t√™n ng∆∞·ªùi sau c√°c t·ª´ kh√≥a: "cho", "c·ªßa", "b√°n cho", "giao cho", "anh", "ch·ªã", "c√¥", "ch√∫", "b√°c".
           - V√≠ d·ª•: "L·∫•y 5 bao xi mƒÉng cho anh H√πng" -> customer_name: "Anh H√πng"
           - V√≠ d·ª•: "C·ªßa ch·ªã Lan n·ª£ nh√©" -> customer_name: "Ch·ªã Lan"
           - N·∫øu kh√¥ng t√¨m th·∫•y t√™n ng∆∞·ªùi c·ª• th·ªÉ, ƒë·ªÉ null.
        2. **product_name**: ∆Øu ti√™n mapping theo "DANH S√ÅCH S·∫¢N PH·∫®M G·ª¢I √ù" ·ªü tr√™n. N·∫øu kh√¥ng kh·ªõp, l·∫•y nguy√™n vƒÉn l·ªùi n√≥i.
        3. **quantity**: S·ªë l∆∞·ª£ng (s·ªë th·ª±c).
        4. **unit**: ƒê∆°n v·ªã t√≠nh (bao, c√°i, th√πng, kg...).
        5. **is_debt**: True n·∫øu c√¢u n√≥i c√≥ t·ª´ "n·ª£", "ghi s·ªï", "thi·∫øu", "tr·∫£ sau". False n·∫øu tr·∫£ ti·ªÅn m·∫∑t/chuy·ªÉn kho·∫£n.

        C√¢u kh√°ch n√≥i: "{message}"
        
        Output JSON format: 
        {{ 
            "customer_name": "T√™n Kh√°ch ho·∫∑c null", 
            "items": [
                {{ "product_name": "T√™n SP", "quantity": 1.0, "unit": "ƒê∆°n v·ªã" }}
            ], 
            "is_debt": false, 
            "original_message": "..." 
        }}
        """
        
        # G·ªçi qua h√†m an to√†n ƒë√£ c√≥ retry
        response = generate_content_safe(model, prompt)
        
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = json.loads(text)
        data['original_message'] = message
        return DraftOrderResponse(**data)

    except exceptions.ResourceExhausted:
        print("‚ùå H·∫øt Quota Google (429) - ƒê√£ th·ª≠ l·∫°i nh∆∞ng v·∫´n th·∫•t b·∫°i.")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message + " (L·ªói: H·ªá th·ªëng qu√° t·∫£i, th·ª≠ l·∫°i sau)"
        )
    except Exception as e:
        print(f"‚ùå L·ªói Parse: {e}")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message
        )

@app.post("/api/parse-order", response_model=DraftOrderResponse)
async def parse_order(request: NaturalLanguageOrderRequest):
    print(f"üì© Parse Order cho Owner {request.owner_id}: {request.message}")
    result = await parse_order_with_rag(request.message, request.owner_id)
    return result

@app.post("/api/orders/ai/transcribe")
async def transcribe_audio(audio: UploadFile = File(...)):
    try:
        audio_bytes = await audio.read()
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        response = generate_content_safe(model, [
            "Ch√©p l·∫°i n·ªôi dung ƒëo·∫°n ghi √¢m n√†y b·∫±ng ti·∫øng Vi·ªát:",
            {"mime_type": "audio/webm", "data": audio_bytes}
        ])
        
        return {"success": True, "text": response.text.strip()}
    except Exception as e:
        print(f"‚ùå L·ªói Audio: {e}")
        return {"success": False, "message": str(e)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)