import os
import json
import uvicorn
import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File
from dotenv import load_dotenv
from app.models import NaturalLanguageOrderRequest, DraftOrderResponse, ProductSyncRequest
from app.services.rag_service import rag_service
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core import exceptions

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

app = FastAPI(title="BizFlow AI Service (Stable)")

# --- C·∫§U H√åNH MODEL ---
# S·ª¨ D·ª§NG 1.5 FLASH ƒê·ªÇ C√ì QUOTA CAO H∆†N, √çT B·ªä L·ªñI 429
GENERATIVE_MODEL_NAME = "gemini-2.5-flash" 

@app.post("/api/products/sync")
async def sync_products(request: ProductSyncRequest):
    data = [p.dict() for p in request.products]
    rag_service.sync_products(request.owner_id, data)
    return {"status": "success", "count": len(data)}

# --- H√ÄM G·ªåI GEMINI C√ì C∆† CH·∫æ RETRY ---
# N·∫øu g·∫∑p l·ªói 429 (ResourceExhausted), t·ª± ƒë·ªông ƒë·ª£i v√† th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn
@retry(
    retry=retry_if_exception_type(exceptions.ResourceExhausted),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def generate_content_safe(model, prompt):
    return model.generate_content(prompt)

async def parse_order_with_rag(message: str, owner_id: str) -> DraftOrderResponse:
    try:
        # 1. T√¨m ki·∫øm RAG
        relevant_products = rag_service.search_products(owner_id, message)
        
        context_str = ""
        if relevant_products:
            context_str = "DANH S√ÅCH S·∫¢N PH·∫®M TRONG KHO (G·ª£i √Ω):\n"
            for p in relevant_products:
                context_str += f"- T√™n: {p['original_name']} | Gi√°: {p['price']} | ƒê∆°n v·ªã: {p['unit']}\n"
        else:
            context_str = "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o trong kho kh·ªõp v·ªõi c√¢u n√≥i."

        # 2. G·ªçi Gemini
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        prompt = f"""
        B·∫°n l√† nh√¢n vi√™n b√°n h√†ng. H√£y tr√≠ch xu·∫•t ƒë∆°n h√†ng t·ª´ c√¢u n√≥i kh√°ch h√†ng th√†nh JSON.
        
        {context_str}
        
        QUY T·∫ÆC:
        1. **product_name**: ∆Øu ti√™n d√πng t√™n trong danh s√°ch g·ª£i √Ω n·∫øu kh·ªõp.
        2. **quantity**: S·ªë l∆∞·ª£ng (s·ªë th·ª±c).
        3. **unit**: ƒê∆°n v·ªã t√≠nh.
        4. **customer_name**: T√™n kh√°ch (n·∫øu c√≥).
        5. **is_debt**: True n·∫øu n·ª£.

        C√¢u kh√°ch n√≥i: "{message}"
        
        Output JSON: {{ "customer_name": null, "items": [{{ "product_name": "...", "quantity": 1, "unit": "..." }}], "is_debt": false, "original_message": "..." }}
        """
        
        # G·ªçi qua h√†m an to√†n ƒë√£ c√≥ retry
        response = generate_content_safe(model, prompt)
        
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = json.loads(text)
        data['original_message'] = message
        return DraftOrderResponse(**data)

    except exceptions.ResourceExhausted:
        print("‚ùå H·∫øt Quota Google (429) - ƒê√£ th·ª≠ l·∫°i nh∆∞ng v·∫´n th·∫•t b·∫°i.")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message + " (L·ªói: H·ªá th·ªëng qu√° t·∫£i, th·ª≠ l·∫°i sau)"
        )
    except Exception as e:
        print(f"‚ùå L·ªói Parse: {e}")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message
        )

@app.post("/api/parse-order", response_model=DraftOrderResponse)
async def parse_order(request: NaturalLanguageOrderRequest):
    print(f"üì© Parse Order cho Owner {request.owner_id}: {request.message}")
    result = await parse_order_with_rag(request.message, request.owner_id)
    return result

@app.post("/api/orders/ai/transcribe")
async def transcribe_audio(audio: UploadFile = File(...)):
    try:
        audio_bytes = await audio.read()
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        response = generate_content_safe(model, [
            "Ch√©p l·∫°i n·ªôi dung ƒëo·∫°n ghi √¢m n√†y b·∫±ng ti·∫øng Vi·ªát:",
            {"mime_type": "audio/webm", "data": audio_bytes}
        ])
        
        return {"success": True, "text": response.text.strip()}
    except Exception as e:
        print(f"‚ùå L·ªói Audio: {e}")
        return {"success": False, "message": str(e)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)